{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torchvision import datasets, transforms\n",
    "from kymatio.torch import Scattering2D\n",
    "import torchvision.transforms.functional as functional\n",
    "import numpy as np\n",
    "from kymatio.torch import Scattering2D\n",
    "from PIL import Image\n",
    "import os, re, sys\n",
    "import umap\n",
    "import ImageFolderWithPaths as IF\n",
    "import s2Net_orientation as network\n",
    "import data_setup as DS\n",
    "import network_function as NF\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class_names = ['IM', ]  # class of image ('apple, orange, etc')\n",
    "s2 = {'name': [], 'par': {}, 'per': {}, 'quart': {}}\n",
    "\n",
    "n_cores = 0\n",
    "im_size = (256, 256)\n",
    "J = 5  # number of scales\n",
    "L = 8  # number of orientations\n",
    "\n",
    "j1 = 1\n",
    "layer1_orientation = 1\n",
    "\n",
    "\n",
    "data_dir = \"Visualize_EG\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class s2Net(nn.Module):\n",
    "    def __init__(self, J, L, layer1_orientation, j1):\n",
    "        super(s2Net, self).__init__()\n",
    "\n",
    "        self.l1 = layer1_orientation\n",
    "\n",
    "        self.norm_index = []\n",
    "\n",
    "        # Define index for parallel and perpendicular filters\n",
    "\n",
    "        self.per_layer1_index = []\n",
    "        self.per_layer2_index = []\n",
    "        self.par_layer1_index = []\n",
    "        self.par_layer2_index = []\n",
    "        self.quarter_layer1_index = []\n",
    "        self.quarter_layer2_index = []\n",
    "\n",
    "        for j2 in range(j1 + 1, J):\n",
    "            for l2 in range(L):\n",
    "\n",
    "                coeff_index_layer2 = layer1_orientation * L * (J - j1 - 1) + l2 + L * (j2 - j1 - 1) + (L ** 2) * \\\n",
    "                                     (j1 * (J - 1) - j1 * (j1 - 1) // 2)\n",
    "\n",
    "                coeff_index_layer1 = layer1_orientation + j1 * L\n",
    "\n",
    "                # parallel\n",
    "                if layer1_orientation == l2:\n",
    "                    self.par_layer1_index.append(coeff_index_layer1)\n",
    "                    self.par_layer2_index.append(coeff_index_layer2)\n",
    "                # perpendicular\n",
    "                if l2 == (layer1_orientation + (L / 2)) or l2 == (layer1_orientation - (L / 2)):\n",
    "                    self.per_layer1_index.append(coeff_index_layer1)\n",
    "                    self.per_layer2_index.append(coeff_index_layer2)\n",
    "                # 45 degrees\n",
    "                if l2 == (layer1_orientation + (L // 4)) or l2 == (layer1_orientation - (L // 4)):\n",
    "                    self.quarter_layer1_index.append(coeff_index_layer1)\n",
    "                    self.quarter_layer2_index.append(coeff_index_layer2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze()\n",
    "        sz = x.shape\n",
    "\n",
    "        # Average pooling across different spatial location\n",
    "        sti = x.mean((len(sz) - 2, len(sz) - 1))  # 1d array of values\n",
    "\n",
    "        scat_coeffs_parallel_order_2 = sti[self.par_layer2_index,] / sti[self.par_layer1_index,]\n",
    "        scat_coeffs_per_order_2 = sti[self.per_layer2_index,] / sti[self.per_layer1_index,]\n",
    "        scat_coeffs_quart_order_2 = sti[self.quarter_layer2_index,] / sti[self.quarter_layer1_index,]\n",
    "\n",
    "        # Return normalized s2 coefficient - activation\n",
    "        return  scat_coeffs_parallel_order_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "dataloaders, device, dataset_sizes, scattering = DS.setup(im_size, class_names, data_dir, n_cores, J, L)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "        scattering = scattering.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "s2_Net = s2Net(J, L, layer1_orientation, j1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IM\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for label in class_names:\n",
    "        print(label)\n",
    "        inputs = dataloaders[label]\n",
    "        for i, ele in enumerate(inputs, 0):\n",
    "            data, n1, path = ele\n",
    "            # Get the name of the image from the path\n",
    "            label = path[0]\n",
    "            label = re.split(\"/\", label)\n",
    "            label = label[-1]\n",
    "\n",
    "            # Load image into device\n",
    "            data = data.to(device)\n",
    "\n",
    "            # Run network\n",
    "            output_parallel, output_per, output_quart = s2_Net(scattering(data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0993)\n"
     ]
    }
   ],
   "source": [
    "print(output_parallel)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'torch.Size' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-17-7878ff07f3f3>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0moutput_parallel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'torch.Size' object is not callable"
     ]
    }
   ],
   "source": [
    "output_parallel.shape()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-fe157445",
   "language": "python",
   "display_name": "PyCharm (McCloskey SP22)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}